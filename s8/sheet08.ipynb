{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb881b440faff8e8427d5a2861f39e9f",
     "grade": false,
     "grade_id": "h00",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Osnabr√ºck University - Machine Learning (Summer Term 2020) - Prof. Dr.-Ing. G. Heidemann, Ulf Krumnack, Axel Schaffland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0363ecd47553f55d98a7188069b1912a",
     "grade": false,
     "grade_id": "h01",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Exercise Sheet 08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb4ca38ee6b663a61b63a343fea85f20",
     "grade": false,
     "grade_id": "h02",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This week's sheet should be solved and handed in before the end of **Saturday, June 27, 2020**. If you need help (and Google and other resources were not enough), feel free to contact your groups' designated tutor or whomever of us you run into first. Please upload your results to your group's Stud.IP folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "393f5ccee17223809837c9aff1cb6f33",
     "grade": false,
     "grade_id": "cell-43f31bf558c5a8ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The second half of this sheet and the following Sheet 09 will be a recap of previous topics, to help you prepare for the final exam.\n",
    "\n",
    "Also if you hit any question that should be discussed in more detail in the next practice session, please let us know."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c8e62347c7b28f3e99d6deed053b2320",
     "grade": false,
     "grade_id": "cell-78e418c8c7c6b9cb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 0: Math recap (Conditional Probability) [0 Points]\n",
    "\n",
    "This exercise is supposed to be very easy and is voluntary. There will be a similar exercise on every sheet. It is intended to revise some basic mathematical notions that are assumed throughout this class and to allow you to check if you are comfortable with them. Usually you should have no problem to answer these questions offhand, but if you feel unsure, this is a good time to look them up again. You are always welcome to discuss questions with the tutors or in the practice session. Also, if you have a (math) topic you would like to recap, please let us know."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "855316bdf01ce31dab06b89382d0c83f",
     "grade": false,
     "grade_id": "math-cprob-q1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** Explain the idea of conditional probability. How is it defined?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cdd8edfccc04a31d9a983866800a57ca",
     "grade": true,
     "grade_id": "math-cprob-a1",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46198461fba50cb38ba7278aca6b935c",
     "grade": false,
     "grade_id": "math-cprob-q2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**b)** What is Bayes' theorem? What are its applications?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe506eb4d056aad3a69041b3e97ee42c",
     "grade": true,
     "grade_id": "math-cprob-a2",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b1e731d96f98286b8a7c10c0ce192ee",
     "grade": false,
     "grade_id": "math-cprob-q3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**c)** What does the law of total probability state? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c694bdf071196e589958260e49ab3fdd",
     "grade": true,
     "grade_id": "math-cprob-a3",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4ff0ff7db2c95c417448bc49284aea41",
     "grade": false,
     "grade_id": "ex2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 1: MLP and RBFN [10 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "89c37df6a4896a21d1977f79290e3d91",
     "grade": false,
     "grade_id": "ex2_intro",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "This exercise is aimed at deepening the understanding of Radial Basis Function Networks and how they relate to Multilayer Perceptrons. Not all of the answers can be found directly in the slides - so when answering the (more algorithmic) questions, first take a minute and think about how you would go about solving them and if nothing comes to mind search the internet for a little bit. If you are interested in a real life application of both algorithms and how they compare take a look at this paper: [Comparison between Multi-Layer Perceptron and Radial Basis Function Networks for Sediment Load Estimation in a Tropical Watershed](http://file.scirp.org/pdf/JWARP20121000014_80441700.pdf)\n",
    "\n",
    "![Schematic of a RBFN](RBFN.png)\n",
    "\n",
    "We have prepared a little example that shows how radial basis function approximation works in Python. This is not an example implementation of a RBFN but illustrates the work of the hidden neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from numpy.random import uniform\n",
    "\n",
    "from scipy.interpolate import Rbf\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "def func(x, y):\n",
    "    \"\"\"\n",
    "    This is the example function that should be fitted.\n",
    "    Its shape could be described as two peaks close to\n",
    "    each other - one going up, the other going down\n",
    "    \"\"\"\n",
    "    return (x + y) * np.exp(-4.0 * (x**2 + y**2))\n",
    "\n",
    "\n",
    "# number of training points (you may try different values here)\n",
    "training_size = 50\n",
    "\n",
    "# sample 'training_size' data points from the input space [-1,1]x[-1,1] ...\n",
    "x = uniform(-1.0, 1.0, size=training_size)\n",
    "y = uniform(-1.0, 1.0, size=training_size)\n",
    "\n",
    "# ... and compute function values for them.\n",
    "fvals = func(x, y)\n",
    "\n",
    "# get the approximation via RBF\n",
    "new_func = Rbf(x, y, fvals)\n",
    "\n",
    "# Plot both functions:\n",
    "# create a 100x100 grid of input values\n",
    "x_grid, y_grid = np.mgrid[-1:1:100j, -1:1:100j]\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, sharey=True, figsize=(10, 6))\n",
    "# This plot represents the original function\n",
    "f_orig = func(x_grid, y_grid)\n",
    "img = ax[0].imshow(f_orig, extent=[-1, 1, -1, 1], cmap='RdBu')\n",
    "ax[0].set(title='Original Function')\n",
    "# This plots the approximation of the original function by the RBF\n",
    "# if the plot looks strange try to run it again, the sampling\n",
    "# in the beginning is random\n",
    "f_new = new_func(x_grid, y_grid)\n",
    "plt.imshow(f_new, extent=[-1, 1, -1, 1], cmap='RdBu')\n",
    "ax[1].set(title='RBF Result', xlim=[-1, 1], ylim=[-1, 1])\n",
    "# scatter the datapoints that have been used by the RBF\n",
    "plt.scatter(x, y, color='black')\n",
    "fig.colorbar(img, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "53e6c796f0502901f1f111fda4023d24",
     "grade": false,
     "grade_id": "ex2_intro2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Radial Basis Function Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "843eb7ad4113f75a0c6f0dbc965e11ec",
     "grade": false,
     "grade_id": "ex2a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### What are radial basis functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5689b524ee20527f70ef0afcbda498ad",
     "grade": true,
     "grade_id": "ex2a_solution",
     "locked": false,
     "points": 1.5,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "Radial basis functions provide a global approximation of a target function by a linear combination of local approximations.\n",
    "\n",
    "**Architecture**:\n",
    "- single layer of neurons (units)\n",
    "- each neuron gets the complete input\n",
    "- neurons have certain weights\n",
    "- there is a unimodal activation function called kernel function\n",
    "- method works locally\n",
    "- neurons contribute to the output vector according to their activation\n",
    "- things to do:\n",
    "    - find suitable input weights (instance-based learning / clustering)\n",
    "    - find radii\n",
    "    - define output weights (perceptron-like rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "db3f6f0431b118780083b72bfd3f0008",
     "grade": false,
     "grade_id": "ex2b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### What is the structure of a RBFN? You may also use the notion from the above included picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a39a5aabd1ef812d743c62f53783aaad",
     "grade": true,
     "grade_id": "ex2b_solution",
     "locked": false,
     "points": 1.5,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "An RBNF is a network with a single layer of neurons (hidden layer) where each of the neurons gets the complete input. The output is a global approximation of the target function that arises from a linear combination of the local approximations which are the outputs of each neuron's activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "616136fc39234c7a2471b4fca69a8983",
     "grade": false,
     "grade_id": "ex2c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### How is a RBFN trained?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b34cadc5a56e11dbe7a7b7afbd20c7b9",
     "grade": true,
     "grade_id": "ex2c_solution",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "The training is a three step process:\n",
    "- find suitable input weights by instance based learning or clustering\n",
    "- find suitable radii of influence\n",
    "- find output weights by using a perceptron-like rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "48193a09eb2de5d7346e4d4c4df375b2",
     "grade": false,
     "grade_id": "ex2_intro3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Comparison to the Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bfd0472e7a522f91f5ec6b44ab73f5de",
     "grade": false,
     "grade_id": "ex2d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### What do both models have in common? Where do they differ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a3ebb0013c85f99414937e2faf60593f",
     "grade": true,
     "grade_id": "ex2d_solution",
     "locked": false,
     "points": 1.5,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "**Effect of adaptation step:**\n",
    "- **RBF**: only local on input area\n",
    "- **MLP**: may change all weights and therefore the performance on the whole data set\n",
    "\n",
    "**Architectural params:**\n",
    "- **RBF**: only #basis functions (easy to interpret)\n",
    "- **MLP**: #layers, #neurons (difficult to interpret)\n",
    "\n",
    "**Adaptation params:**\n",
    "- **RBF**: decoupled and easy to interpret (clustering params, radii, stepsize)\n",
    "- **MLP**: coupled and interacting in complex manner (stepsize, momentum etc.)\n",
    "\n",
    "**In common:**\n",
    "- both are feed-forward nets\n",
    "- non-linear activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7653a1317cbde9eeb5f7c5bb69e0f916",
     "grade": false,
     "grade_id": "ex2e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### How can classification in both networks be visualized?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73186d27f52007f372b4690524d09f8c",
     "grade": true,
     "grade_id": "ex2e_solution",
     "locked": false,
     "points": 1.5,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "- An MLP naturally separates the classes with hyperplanes in the input space\n",
    "- RBF separate class distributions by localizing radial basis functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4492d9d9b4f66662527046a11aa7db60",
     "grade": false,
     "grade_id": "ex2f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### When would you use a RBFN instead of a Multilayer Perceptron?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "81583cddf2a3d90cc17902ad1585d182",
     "grade": true,
     "grade_id": "ex2f_solution",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "MLPs are not as good as RBF in dealing with noisy data sets. It's probably a good idea to use RBF when there's a lot of noise in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "89444826bba181874e0b85ac48fa4dfd",
     "grade": false,
     "grade_id": "ex01",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap 1: Concept Learning [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6dd50cc83285c1232c1195d63abffe81",
     "grade": false,
     "grade_id": "ex01a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### a) Concept Learning\n",
    "\n",
    "What is Concept Learning? Is it supervised? Is it local?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f6a8f2101ff00d3bda8a4cc23edeab47",
     "grade": true,
     "grade_id": "ex01a_solution",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The problem that is considered in concept learning is 'how to learn general concepts from specific examples'. A concept can be represented by a boolean function which assigns true to the appropriate entities.  \n",
    "Since we need to know whether an example belongs to the concept or not during the learning, it's supervised.  \n",
    "Concepts can be learned using various different learning approaches and therefore there could be local and non-local approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3d737190c7f553a49494e7eb419fb34c",
     "grade": false,
     "grade_id": "ex01b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### b) Find-S\n",
    "Describe the Find-S Algorithm in pseudo code. What is its inductive bias? What are its advantages and drawbacks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "18e819151f0265e4150ffa80886a3189",
     "grade": true,
     "grade_id": "ex01b_solution",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- init $h$ to the most specific hypothesis\n",
    "- for each positive training instance $x$\n",
    "    - for each attribute constraint $a_i \\in h$\n",
    "        - if $a_i$ is not satisfied by $x$\n",
    "            - replace $a_i$ in $h$ by the next more general constraint that is satisfied by $x$\n",
    "- return $h$\n",
    "\n",
    "**Inductive Bias**:\n",
    "- the target function must be inside of the hypotheses set\n",
    "- all instances are going to be negative, unless the opposite is entailed by its knowledge\n",
    "\n",
    "**Drawbacks**:\n",
    "- learns nothing from negative examples\n",
    "- can't tell whether it has learned the concept\n",
    "- can't tell whether training data is inconsistent\n",
    "- picks maximally specific $h$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "831be53b6f45c70670bc74332cda5e8a",
     "grade": false,
     "grade_id": "ex01c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### c) Hypotheses space\n",
    "\n",
    "What is the hypotheses space for Candidate-Elimination used in the lecture?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5be9a36e155ebc23c7b3fc18af3d8a53",
     "grade": true,
     "grade_id": "ex01c_solution",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The hypotheses space is the set of all hypotheses between the most general and the most specific hypotheses, basically the set that contains every possible hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5299e31e4c11bbbe108c8acdc632dfa7",
     "grade": false,
     "grade_id": "ex02",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap 2: Decision Trees [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a02502f7aa7e6b21ac550b63992ee4fb",
     "grade": false,
     "grade_id": "ex02a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### a) Overfitting\n",
    "What is overfitting? How can it be avoided?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d3952e567abbde69a5fdffd4f5f3defa",
     "grade": true,
     "grade_id": "ex02a_solution",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Overfitting means fitting the noise of the training data which prevents good generalization properties for unseen data sets. It can be avoided by stopping to grow the tree when the data split is no longer statistically significant or by post-pruning after building up the complete tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d1a0d5e1bc5af31544ce463bd6309c97",
     "grade": false,
     "grade_id": "ex02b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### b) Pruning\n",
    "\n",
    "Name one method for pruning a decision tree and describe it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7cb89deabdf0ceeebcf18306b7b0e929",
     "grade": true,
     "grade_id": "ex02b_solution",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Reduced error pruning** removes nodes to achieve better generalization on the validation set.  \n",
    "The method stops when further pruning would decrease the performance on the validation set below the original tree. First, the impact on the validation set for pruning a node is evaluated for each possible node. The node that most improves the accuracy on the validation set gets removed afterwards.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "581ce55f66d4fa663c711d4f6f8083a2",
     "grade": false,
     "grade_id": "ex02c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### c) Information gain\n",
    "What are entropy and information gain? Provide explanation and formulae. How are they used in ID3?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a03b8a2efba5138af0ef701ebc4c8079",
     "grade": true,
     "grade_id": "ex02c_solution",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The entropy $E \\in [0, 1]$ measures the impurity of a set of training examples $S$ and is defined as follows:  \n",
    "\n",
    "$E(S) = -p_+ \\thinspace log_2 \\thinspace p_+ \\thinspace - \\thinspace p_- \\thinspace log_2 \\thinspace p_-$  \n",
    "\n",
    "$p_+ := $ proportion of positive examples in $S$  \n",
    "\n",
    "$p_- := $ proportion of negative examples in $S$\n",
    "\n",
    "A set $S$ that contains only one class of examples would be entirely pure and therefore have an entropy of $0$. On the other hand, for a set that has as many examples from one class as from the other, the entropy would be $1$, because of the maximum impurity of the set.  \n",
    "\n",
    "The information gain is the expected reduction in entropy for a set $S$ due to sorting on a certain attribute $A$. It is defined as:  \n",
    "\n",
    "$G(S, A) = E(S) - \\sum_v E(S_v) \\cdot \\frac{|S_v|}{|S|}$  \n",
    "\n",
    "$S_v$ is the subset of $S$ for which $A$ has value $v$. That means that the entropy values for each $S_v$ weighted with their proportion of the whole set are subtracted from the entropy. It is easy to see that the information gain is maximal when the $S_v$ are pure. The other extreme would be totally chaotic $S_v$ which would lead to a low information gain.\n",
    "\n",
    "The ID3 algorithm builds the tree based on the information gain achieved by attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2523c25781782f0b76adb0bb007f71a9",
     "grade": false,
     "grade_id": "ex03",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap 3: Data Mining [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0854d423cad5f1d191f7fdc7fbf8a54",
     "grade": false,
     "grade_id": "ex03a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### a) Missing values\n",
    "\n",
    "How can you deal with missing values? Name an important algorithm and explain how to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "50d5bcf42266796846c068c0305106d1",
     "grade": true,
     "grade_id": "ex03a_solution",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are different approaches to deal with missing values:\n",
    "- take mean for missing attribute (artifacts)\n",
    "- estimate model to predict missing values (linear regression) -> artificial concentration of values along regression lines\n",
    "- estimate data distribution and generate missing values by random samples from that distribution\n",
    "- Expectation Maximization (EM) algorithm\n",
    "\n",
    "One important algorithm to deal with missing value situations is the EM algorithm. It's an iterative method to find (local) maximum likelihood estimates of parameters in statistical models, where the model depends on unobserved latent variables. The EM iteration alternates between performing an expectation (E) step, which creates a function for the expectation of the log-likelihood evaluated using the current estimate for the parameters, and a maximization (M) step, which computes parameters maximizing the expected log-likelihood found on the E step. These parameter-estimates are then used to determine the distribution of the latent or missing variables in the next E step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e718969e5c226ca2e25eb4ed3aaab07e",
     "grade": false,
     "grade_id": "ex03b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### b) Outliers\n",
    "\n",
    "What are outliers? Can we detect them? If so, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fa13ef09df2fc9dfbf0cf5f037441b93",
     "grade": true,
     "grade_id": "ex03b_solution",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Outliers are data values that do not seem representative for the rest of the data, because they are 'far away' from the rest of the data points and do not fit the expectation. There are numerous causes of outliers, e.g.:\n",
    "- technical / measurement errors\n",
    "- unexpected true effect\n",
    "- data with high variation\n",
    "\n",
    "To consider a data point an outlier, we need to define what is regular. One approach to detect outliers is the so called z-test. It considers the distances of points from the mean of the data set and checks whether the distances exceed some limit. If the distance of a point exceeds this limit, the point is considered an outlier. A more sophisticated version of this is called Rosner test where those outliers are removed iteratively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4dde048627577df25283825482f2055f",
     "grade": false,
     "grade_id": "ex03c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### c) Expectation Maximization\n",
    "What does the Q-function express in the EM algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "976ec12fd1ac5e884bb64e6967a0ed8c",
     "grade": true,
     "grade_id": "ex03c_solution",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The Q-function expresses the averaged (expected) likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e98250179ac671cb076df4339abd91a5",
     "grade": false,
     "grade_id": "ex04",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap 4: Clustering [4 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "373adcc0111aa5f139a3bd5b7f74e062",
     "grade": false,
     "grade_id": "ex04a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### a) Clustering\n",
    "\n",
    "Explain the difference between single-linkage and complete-linkage clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e0e3f4c5c1a2fce02a2671e99ee34746",
     "grade": true,
     "grade_id": "ex04a_solution",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Single-linkage clustering employs the minimum cluster distance $D_{min}$ (distance of closest points between two clusters).\n",
    "\n",
    " Complete-linkage clustering employs the maximum cluster distance $D_{max}$ (max distance between two points of the two clusters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d72601f8cd17c51c838b96fbb3f5d5aa",
     "grade": false,
     "grade_id": "ex04b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### b) Metrics\n",
    "\n",
    "Name three different distance measures and briefly explain them. Check the metric axioms for one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1813d29faac7affb585aa5f0dc0798f5",
     "grade": true,
     "grade_id": "ex04b_solution",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Euclidean distance**: Straight-line distance between two points in Euclidean space\n",
    "    - $d(x, y) = \\sqrt{\\sum_i (x_i - y_i)^2}$\n",
    "- **Manhattan distance**: Distance between two points is the sum of the absolute differences of their Cartesian coordinates\n",
    "    - $d(x, y) = \\sum_i |x_i - y_i|$\n",
    "- **Hamming distance**: Number of positions where two strings of equal length differ\n",
    "    - $d(x, y) = |\\{i \\in \\{1, ..., n\\} \\thinspace | \\thinspace x_i \\neq y_i\\}|$\n",
    "\n",
    "**Metric axioms for Euclidean distance:**\n",
    "\n",
    "- identity of indiscernibles: $d(x, y) = 0 \\iff x = y$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "539b0a8be1e2aeddcca1933b7c3e7f04",
     "grade": false,
     "grade_id": "ex04c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### c) Mixture models\n",
    "\n",
    "What is a mixture model? Explain. Can you provide a formula?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "718e7afbc96985c166fa509dbc957246",
     "grade": true,
     "grade_id": "ex04c_solution",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It's a mixture of several components, where each component has a simple parametric form (such as a Gaussian). \n",
    "We assume each data point belongs to one of the components, and we try to infer the distribution for each component separately. In  general, a mixture model assumes the data points are generated by the following process: first we sample $z$, and then we sample the observables $x$ from a distribution which depends on $z$, i.e. $p(z, x) = p(z) p(x|z)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3850c1608d8fe96f63823008d11c71b2",
     "grade": false,
     "grade_id": "ex05",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap 5: Dimension Reduction [2 Points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a033c54e38f456ac44116663f495beea",
     "grade": false,
     "grade_id": "ex05a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### a) Visualization\n",
    "\n",
    "Name three different data visualization techniques to visualize high dimensional data. Explain one in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d23c78e45b73046de3c8529c351df01",
     "grade": true,
     "grade_id": "ex05a_solution",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Scatterplot matrix**: Project on two of the dimensions and display all combinations as matrix of 2D plots\n",
    "- **Glyphs**: Map each dimension onto the parameters of a geometrical figure\n",
    "- **Chernoff Faces**: Parameters are mapped to facial features\n",
    "    - The human visual system is particularly sensitive for faces, i.e. we are very good at interpreting and recognizing human faces. Chernoff used faces to make use of this property when representing high dimensional data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8802c24ea5a82ef6a8542b0dc33de4b2",
     "grade": false,
     "grade_id": "ex05b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### b) PCA\n",
    "\n",
    "Draw a few data points (ASCII arts or on a sheet of paper) and mark the principal components. What are the principal components?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e8e43203e4824dae30c77cd382c12812",
     "grade": true,
     "grade_id": "ex05b_solution",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"PC.png\" width=\"400\"/>\n",
    "\n",
    "PCs are vectors pointing in the direction of largest variance. Their magnitude (length) expresses that variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5ba0948130b01d9ab0267c8007d9312d",
     "grade": false,
     "grade_id": "ex05c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### c) Covariance matrix\n",
    "What does a covariance matrix express? How is it computed from data? How is it used in PCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "90cb090ef14311e4ea69d41da8684682",
     "grade": true,
     "grade_id": "ex05c_solution",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The covariance matrix tells you how much one feature in your data set covariates with another feature in the data set.\n",
    "On the diagonal, you just have the variance of the individual features and the non-diagonal elements you see how feature $i$ covariates with feature $j$. If you normalize it, you get the correlation matrix with values between $-1$ and $1$ which actually tell how much two features correlate.\n",
    "\n",
    "Compute covariance matrix:\n",
    "$C(X) = E((X - \\mu)(X - \\mu)^T)$ where $\\mu$ is the expected value (mean vector) of the data set.\n",
    "\n",
    "The covariance matrix is an essential part of PCA, because the PCs are the eigenvectors of this matrix."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda475831754d4f421c8b9b78a005f24ea9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}