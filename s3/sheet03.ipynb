{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "12d4757fd3d4e68c031c5b38a8639e44",
     "grade": false,
     "grade_id": "cell-394682a21c078310",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Osnabr√ºck University - Machine Learning (Summer Term 2019) - Prof. Dr.-Ing. G. Heidemann, Ulf Krumnack, Axel Schaffland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1c06dfce29b0acd25cae4015ca1285b1",
     "grade": false,
     "grade_id": "cell-e9802371e834eb85",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise Sheet 03: Basics of Data Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e32cca4d055b292a8160e3f10594bbab",
     "grade": false,
     "grade_id": "cell-f790e30691d4d590",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This week's sheet should be solved and handed in before the end of **Saturday, May 16, 2020**. If you need help (and Google and other resources were not enough), feel free to contact your groups designated tutor or whomever of us you run into first. Please upload your results to your group's studip folder.\n",
    "\n",
    "There are a lot of implementations with fewer theory questions on this sheet, but don't worry: To be able to implement most of the code, you have to understand the theory.\n",
    "\n",
    "This week's assignments make use of two packages: `numpy` and `matplotlib`. We already expected you to install those as part of sheet 0 (`conda env create -f ml.yml`). If you did not do so, go back to those instructions or just run the following command in the `terminal`/`cmd.exe` to do so. This will also upgrade your current installation.\n",
    "\n",
    "    conda install jupyter numpy matplotlib\n",
    "\n",
    "One note about `matplotlib`: If you run code which contains a plot like the cell below, it can sometimes take a while to execute the code and show the results. During that process the invocation count will be shown as a little Asterisk (\\*) like this:\n",
    "\n",
    "    In [*]:\n",
    "    \n",
    "Just be patient for a few seconds. \n",
    "\n",
    "A second note about `matplotlib`: For interactive plots you have to call the magic function `%matplotlib` with `notebook` as argument (`%matplotlib notebook`) for inline plots which are saved inside the notebook use `inline` as argument.\n",
    "\n",
    "The following cell tests if `numpy` and `matplotlib` are installed and work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e38cf869abb5bb404c583d588e050e4c",
     "grade": false,
     "grade_id": "cell-43b756541dad5bdc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "\n",
    "assert importlib.util.find_spec('numpy') is not None , 'numpy not found'\n",
    "assert importlib.util.find_spec('matplotlib') is not None, 'matplotlib not found'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figure_intro = plt.figure('Example plot')\n",
    "plt.plot(np.random.randn(1000, 1))\n",
    "figure_intro.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "acb676566a95e7b2a1d4d44eeff3b767",
     "grade": false,
     "grade_id": "math-matrix",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 0: Math recap (matrices and linear mappings) [0 Points]\n",
    "\n",
    "This exercise is supposed to be very easy and is voluntary. There will be a similar exercise on every sheet. It is intended to revise some basic mathematical notions that are assumed throughout this class and to allow you to check if you are comfortable with them. Usually you should have no problem to answer these questions offhand, but if you feel unsure, this is a good time to look them up again. You are always welcome to discuss questions with the tutors or in the practice session. Also, if you have a (math) topic you would like to recap, please let us know."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "607871e43aba6a9036a1decaea2dfa04",
     "grade": false,
     "grade_id": "math-matrix-q1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** What is a *matrix*? How is it usually written?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d6810d6862cdde6b4ed37c8dd42a2179",
     "grade": true,
     "grade_id": "math-matrix-a1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1caa2cca091eb1822e38f81ae904626a",
     "grade": false,
     "grade_id": "math-matrix-q2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**b)** How is *addition of matrices* defined? What about *matrix multiplication*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "01a22be201f80d235514a258966bdd8b",
     "grade": true,
     "grade_id": "math-matrix-a2",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ecc2bf97ccf3546968a6f8b7da2656ae",
     "grade": false,
     "grade_id": "math-matrix-q3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**c)** What is a *linear mapping*? What is the relation to matrices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "203d58dbd5f1d0a202d1a66a54fd66d0",
     "grade": true,
     "grade_id": "math-matrix-a3",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "54afd21f0c5f5e547759e7c0a1ed464f",
     "grade": false,
     "grade_id": "1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 1: Rosner test [5 Points]\n",
    "\n",
    "The Rosner test is an iterative procedure to remove outliers of a data set via a z-test. In this exercise you will implement it and apply it to a sample data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d82297f0a89eb3fc4696837945639779",
     "grade": false,
     "grade_id": "1a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### a) Outliers\n",
    "\n",
    "First of all, think about why we use procedures like this and answer the following questions: \n",
    "\n",
    "What are causes for outliers? And what are our options to deal with them? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1781fd2b6c19b6721f71e77b2c55156c",
     "grade": true,
     "grade_id": "1a_answer",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "**Causes of outliers:**\n",
    "- measurement errors (e.g. due to technical errors)\n",
    "- unexpected effect that is actually true\n",
    "- data with high variation\n",
    "\n",
    "**Options to deal with them:**\n",
    "- detect outliers - first define what is regular\n",
    "- options to deal with outliers\n",
    "    - remove (e.g. Rosner test - iteratively remove outliers)\n",
    "    - weight\n",
    "    - remove + fill up gaps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f9bfc15074353da2770f3cbbac0461cb",
     "grade": false,
     "grade_id": "1b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### b) Rosner test\n",
    "\n",
    "In the following you find a stub for the implementation. The dataset is already generated. Now it is your turn to write the Rosner test and detect the outliers in the data. \n",
    "\n",
    "`data` is a `np.array` of `[x, y]` coordinates. `outliers` is a list of `[x, y]` coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7eb285760d0dffc0d3c6cd386bf4dbdb",
     "grade": true,
     "grade_id": "1b_code",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# generate dataset\n",
    "data = list(zip(np.random.uniform(size=100), np.random.normal(size=100)))\n",
    "data += list(zip(np.random.uniform(size=10), np.random.normal(0, 10, size=10)))\n",
    "data = np.array(data)\n",
    "outliers = []\n",
    "\n",
    "# just to check if everything is pretty\n",
    "fig_rosner_data = plt.figure('The Dataset')\n",
    "plt.scatter(data[:,0], data[:,1], marker='x')\n",
    "plt.axis([0, 1, -20, 20])\n",
    "fig_rosner_data.canvas.draw()\n",
    "\n",
    "# Now find the outliers, add them to 'outliers', and remove them from 'data'.\n",
    "# YOUR CODE HERE ###################################\n",
    "while True:\n",
    "    # outliers will be in y direction\n",
    "    y_coords = data[:,1]\n",
    "    mean = np.mean(y_coords)\n",
    "    standard_deviation = np.std(y_coords)\n",
    "    z_values = [abs(val - mean) / standard_deviation for val in y_coords]\n",
    "    max_z = max(z_values)\n",
    "\n",
    "    if max_z <= 3:\n",
    "        break\n",
    "    outliers.append(data[z_values.index(max_z)])\n",
    "    # removes the outlier from the data\n",
    "    data = np.delete(data, z_values.index(max_z), 0)\n",
    "####################################################\n",
    "\n",
    "# plot results\n",
    "outliers = np.array(outliers)\n",
    "fig_rosner = plt.figure('Rosner Result')\n",
    "plt.scatter(data[:,0], data[:,1], c='b', marker='x', label='cleared data')\n",
    "plt.scatter(outliers[:,0], outliers[:,1], c='r', marker='x', label='outliers')\n",
    "plt.axis([0, 1, -20, 20])\n",
    "plt.legend(loc='lower right')\n",
    "fig_rosner.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32194b9eb098b0716692299dbc0f1e28",
     "grade": false,
     "grade_id": "2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 2: p-norm [6 Points]\n",
    "\n",
    "A very well known norm is the euclidean distance. However, it is not the only norm: It is in fact just one of many p-norms where $p = 2$. In this assignment you will take a look at other p-norms and see how they behave.\n",
    "\n",
    "Implement a function `pnorm` which expects a vector $x \\in \\mathcal{R}^n$ and a scalar $p \\geq 1, p \\in \\mathcal{R}$ and returns the p-norm of $x$ which is defined as:\n",
    "\n",
    "$$||x||_p = \\left(\\sum\\limits_{i=1}^n |x_i|^p \\right)^{\\frac{1}{p}}$$\n",
    "\n",
    "*Note:* Even though the norm is only defined for $p \\geq 1$, values $0 < p < 1$ are still interesting. In that case we can not talk about a norm anymore, as the triangle inequality ($||a|| + ||b|| \\geq ||a + b||$) does not hold. We will still take a look at some of these values, so your function should handle them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ec229467f9f1c28ffefc15b7d105967",
     "grade": false,
     "grade_id": "2a_code",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pnorm(x, p):\n",
    "    \"\"\"\n",
    "    Calculates the p-norm of x.\n",
    "    \n",
    "    Args:\n",
    "        x (array): the vector for which the norm is to be computed.\n",
    "        p (float): the p-value (a positive real number).\n",
    "        \n",
    "    Returns:\n",
    "        The p-norm of x.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    res = 0\n",
    "    if isinstance(x, int):\n",
    "        res += abs(x) ** p\n",
    "    else:\n",
    "        for i in x:\n",
    "            res += abs(i) ** p\n",
    "    return res ** (1.0 / p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "13d44eb1a8193785648155adcdfc692f",
     "grade": true,
     "grade_id": "2a_test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 1e-10 is 0.0000000001\n",
    "assert pnorm(1, 2)      - 1          < 1e-10 , \"pnorm is incorrect for x = 1, p = 2\"\n",
    "assert pnorm(2, 2)      - 2          < 1e-10 , \"pnorm is incorrect for x = 2, p = 2\"\n",
    "assert pnorm([2, 1], 2) - np.sqrt(5) < 1e-10 , \"pnorm is incorrect for x = [2, 1], p = 2\" \n",
    "assert pnorm(2, 0.5)    - 2          < 1e-10 , \"pnorm is incorrect for x = 2, p = 0.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bbbcd9561fd078bbd8c740270fac7278",
     "grade": false,
     "grade_id": "2b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Implement another function `pdist` which expects two vectors $x_0 \\in \\mathcal{R}^n, x_1 \\in \\mathcal{R}^n$ and a scalar $p \\geq 1, p \\in \\mathcal{R}$ and returns the distance between $x_0$ and $x_1$ on the p-norm defined by $p$. Again handle $0 < p < 1$ as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50ac04eece9d414f9d3321b9d6b21004",
     "grade": false,
     "grade_id": "2b_code",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pdist(x0, x1, p):\n",
    "    \"\"\"\n",
    "    Calculates the distance between x0 and x1\n",
    "    using the p-norm.\n",
    "    \n",
    "    Arguments:\n",
    "        x0 (array): the first vector.\n",
    "        x1 (array): the second vector.\n",
    "        p (float): the p-value (a positive real number).\n",
    "        \n",
    "    Returns:\n",
    "        The p-distance between x0 and x1.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return pnorm(x1, p) - pnorm(x0, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "efad4b3b463bdade199425f6248f2db2",
     "grade": true,
     "grade_id": "2b_test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# 1e-10 is 0.0000000001\n",
    "assert pdist(1, 2, 2)           - 1          < 1e-10 , \"pdist is incorrect for x0 = 1, x1 = 2, p = 2\"\n",
    "assert pdist(2, 5, 2)           - 3          < 1e-10 , \"pdist is incorrect for x0 = 2, x1 = 5, p = 2\"\n",
    "assert pdist([2, 1], [1, 2], 2) - np.sqrt(2) < 1e-10 , \"pdist is incorrect for x0 = [2, 1], x1 = [1, 2], p = 2\" \n",
    "assert pdist([2, 1], [0, 0], 2) - np.sqrt(5) < 1e-10 , \"pdist is incorrect for x0 = [2, 1], x1 = [0, 0], p = 2\" \n",
    "assert pdist(2, 0, 0.5)         - 2          < 1e-10 , \"pdist is incorrect for x0 = 2, x1 = 0, p = 0.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fca520be56e98a7820f17c8d2c45d8b5",
     "grade": false,
     "grade_id": "2c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now we will compare some different p-norms. Below is part of a code to plot data in nice scatter plots. \n",
    "\n",
    "Your task is to calculate the data to plot. The variable `data` is currently simply filled with zeros. Instead, fill it as follows:\n",
    "\n",
    "- Use the function `np.linspace()` to create a vector of `50` evenly distributed values between `-100` and `100` (inclusively).\n",
    "- Fill `data`: Data is basically the cartesian product of the vector you created before with itself filled up with each value's norm. It should have 2500 rows. Each of the 2500 rows should contain `[x, y, d]`, where `x` is the x coordinate and `y` the y coordinate of a point, and `d` the p-norm of `(x, y)`. Use either `pnorm` or `pdist` to calculate `d`.\n",
    "- Normalize the data in `data[:,2]` (i.e. all d-values) so that they are between 0 and 1.\n",
    "\n",
    "Run your code and take a look at your results. Darker colors mean that a value is further away from the center (0, 0) according to the p-norm used.\n",
    "\n",
    "*Hint:* To give you an idea of how `data` should look like, here is an example for three evenly distributed values between `-1` and `1` and a p-norm with `p = 2`.\n",
    "\n",
    "Before normalization of the d-column:\n",
    "\n",
    "```python\n",
    "data = np.array([[-1.         -1.          1.41421356]\n",
    "                 [-1.          0.          1.        ]\n",
    "                 [-1.          1.          1.41421356]\n",
    "                 [ 0.         -1.          1.        ]\n",
    "                 [ 0.          0.          0.        ]\n",
    "                 [ 0.          1.          1.        ]\n",
    "                 [ 1.         -1.          1.41421356]\n",
    "                 [ 1.          0.          1.        ]\n",
    "                 [ 1.          1.          1.41421356]])\n",
    "```\n",
    "\n",
    "After normalization of the d-column:\n",
    "\n",
    "```python\n",
    "data = np.array([[-1.         -1.          1.        ]\n",
    "                 [-1.          0.          0.70710678]\n",
    "                 [-1.          1.          1.        ]\n",
    "                 [ 0.         -1.          0.70710678]\n",
    "                 [ 0.          0.          0.        ]\n",
    "                 [ 0.          1.          0.70710678]\n",
    "                 [ 1.         -1.          1.        ]\n",
    "                 [ 1.          0.          0.70710678]\n",
    "                 [ 1.          1.          1.        ]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f7e39c5e9582be35094202ef9228217",
     "grade": true,
     "grade_id": "3c_code",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ColorConverter\n",
    "\n",
    "color = ColorConverter()\n",
    "figure_norms = plt.figure('p-norm comparison')\n",
    "\n",
    "# create the linspace vector\n",
    "# YOUR CODE HERE\n",
    "ls = np.linspace(-100, 100, 50)\n",
    "\n",
    "assert len(ls) == 50 , 'ls should be of length 50.'\n",
    "assert (min(ls), max(ls)) == (-100, 100) , 'ls should range from -100 to 100, inclusively.'\n",
    "\n",
    "for i, p in enumerate([1/8, 1/4, 1/2, 1, 1.5, 2, 4, 8, 128]):\n",
    "    # YOUR CODE HERE\n",
    "    data = [[x, y, pnorm([x, y], p)] for x in ls for y in ls]\n",
    "    data = np.array(data)\n",
    "    data[:,2] /= np.max(data[:,2])\n",
    "\n",
    "    assert data[100,2]>0.9 and data[100,2]<1, \"Wrong result for p norm, make sure you use NORM and not pdist!\"\n",
    "    assert all(data[:,2] <= 1), 'The third column should be normalized.'\n",
    "\n",
    "    # Plot the data.\n",
    "    colors = [color.to_rgb((1, 1-a, 1-a)) for a in data[:,2]]\n",
    "    a = plt.subplot(3, 3, i + 1)\n",
    "    plt.scatter(data[:,0], data[:,1], marker='.', color=colors)\n",
    "    a.set_ylim([-100, 100])\n",
    "    a.set_xlim([-100, 100])\n",
    "    a.set_title('{:.3g}-norm'.format(p))\n",
    "    a.set_aspect('equal')\n",
    "    plt.tight_layout()\n",
    "    figure_norms.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4190815a7f49ce242960b85477e1a733",
     "grade": false,
     "grade_id": "3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 3: Expectation Maximization [9 Points]\n",
    "\n",
    "### a) What applications of the EM algorithm did you get to know in the lecture? Describe how EM treats the missing value problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "017dd9778cda78404c9702ea1299b726",
     "grade": true,
     "grade_id": "3a_answer",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "**Applications:**\n",
    "- missing value situations\n",
    "- finite mixture models\n",
    "- train models with hidden variables\n",
    "\n",
    "The EM algorithm is an iterative two step approach:\n",
    "- E-Step: estimate the latent variables\n",
    "- M-Step: maximize the likelihood of the model by adapting the parameters\n",
    "\n",
    "The missing values are basically invented in the EM algorithm. The algorithm tries to find parameters that maximize the log-likelihood of the data given the parameters. The E-Step always estimates the current situation based on the model and the M-Step improves it (maximizes the likelihood) by adapting the parameters. Finally, the procedure converges to a local optimum which could however be arbitrarily far away from the real underlying parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "50300b7a42ecaa5349393425bad81fc0",
     "grade": false,
     "grade_id": "3b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### b) Implement Expectation Maximization for Soft Clustering\n",
    "\n",
    "As some parts of this exercise would require some more knowledge of Python than what was already discussed in the practice sessions we built a small number of templates for you to use. However, if you prefer to do so you are also allowed to just go ahead and implement everything yourself!\n",
    "\n",
    "Use the next cell to implement your own solution or, if you want some more guidance, skip the next cell and continue the exercise at  [Step 1) Load the data](#Step-1%29-Load-the-data).\n",
    "\n",
    "Here is an overview of what you have to do:\n",
    "\n",
    "**1) Load the data:**\n",
    "\n",
    "Load the provided data set. It is stored in `em_normdistdata.txt`. We call the set $X$ and each individual data $x \\in X$.\n",
    "\n",
    "**2) Initialize EM:**\n",
    "\n",
    "Initialize three normal distributions whose parameters will be changed iteratively by the EM to converge close to the original distributions.\n",
    "\n",
    "Each normal distribution $j$ has three parameters: $\\mu_j$ (the mean), $\\sigma_j$ (the standard deviation), $\\alpha_j$ (the proportion of the normal distribution in the mixture, that means $\\sum\\limits_j\\alpha_j=1$).\n",
    "\n",
    "Initialize the three parameters using three random partitions $S_j$ of the data set. Calculate each $\\mu_j$ and $\\sigma_j$ and set $\\alpha_j = \\frac{|S_j|}{|X|}$.\n",
    "\n",
    "**3) Implement the expectation step:**\n",
    "\n",
    "Perform a soft classification of the data samples with the three normal distributions. That means: Calculate the likelihood that a data sample $x_i$ belongs to distribution $j$ given parameters $\\mu_j$ and $\\sigma_j$. Or in other words, what is the likelihood of $x_i$ to be drawn from $N_j(\\mu_j, \\sigma_j)$? When you got the likelihood, weight the result by $\\alpha_j$.\n",
    "\n",
    "As a last step normalize the results such that the likelihoods of a data sample $x_i$ sum up to $1$.\n",
    "\n",
    "**4) Implement the maximization step:**\n",
    "\n",
    "In the maximization step each $\\mu_j$, $\\sigma_j$ and $\\alpha_j$ is updated. First calculate the new means:\n",
    "\n",
    "$$\\mu_j = \\frac{1}{\\sum\\limits_{i=1}^{|X|} p_{ij}} \\sum\\limits_{i=1}^{|X|} p_{ij}x_i$$\n",
    "\n",
    "That means $\\mu_j$ is the weighted mean of all samples, where the weight is their likelihood of belonging to distribution $j$.\n",
    "\n",
    "Then calculate the new $\\sigma_j$. Each new $\\sigma_j$ is the standard deviation of the normal distribution with the new $\\mu_j$, so for the calculation you already use the new $\\mu_j$:\n",
    "\n",
    "$$\\sigma_j = \\sqrt{ \\frac{1}{\\sum\\limits_{i=1}^{|X|} p_{ij}} \\sum\\limits_{i=1}^{|X|} p_{ij} \\left(x_i - \\mu_j\\right)^2 }$$\n",
    "\n",
    "To calculate the new $\\alpha_j$ for each distribution, just take the mean of $p_j$ for each normal distribution $j$.\n",
    "\n",
    "**5) Perform the complete EM and plot your results:**\n",
    "\n",
    "Build a loop around the iterative procedure of expectation and maximization which stops when the changes in all $\\mu_j$ and $\\sigma_j$ are sufficiently small enough.\n",
    "\n",
    "Plot your results after each step and mark which data points belong to which normal distribution. If you don't get it to work, just plot your final solution of the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1151768e2ad255f18086da2569feb3b",
     "grade": true,
     "grade_id": "3b_self",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Free space to implement your own solution -- either use this OR use the following step by step guide. \n",
    "# You may use scipy.stats.norm.pdf for your own implementation.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "155160ce65563c76a18df3dccfbba85a",
     "grade": false,
     "grade_id": "3b1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Step 1) Load the data\n",
    "\n",
    "\n",
    "Load the provided data set. It is stored in `em_normdistdata.txt`. We call the set $X$ and each individual data $x \\in X$. \n",
    "\n",
    "*Hint:* Figure out a way on how numpy can load text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6da9b1d7d87bebb4bba5784d9cff3e33",
     "grade": true,
     "grade_id": "3b1_code",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(file_name):\n",
    "    \"\"\"\n",
    "    Loads the data stored in file_name into a numpy array.\n",
    "    \"\"\"\n",
    "    return np.loadtxt(file_name)\n",
    "\n",
    "assert load_data('em_normdistdata.txt').shape == (200,) , \"The data was not properly loaded.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c38879618eae0d156b639e62aa1bb4f7",
     "grade": false,
     "grade_id": "3b1b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "*Optional:* The data consists of 200 data points drawn from three normal distributions. To get a feeling for the data set you can plot the data with the following cell. Change the number of bins to get a rough idea of how the three distributions might look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a76099f1b76de5a43751342dc8158afb",
     "grade": true,
     "grade_id": "3b1_test",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = load_data('em_normdistdata.txt')\n",
    "fig_data_test = plt.figure('Data overview')\n",
    "# YOUR CODE HERE\n",
    "# You may change the number of bins here\n",
    "plt.hist(data, bins=20)\n",
    "fig_data_test.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "950ceab7618d14e322349e05c53dcd40",
     "grade": false,
     "grade_id": "3b2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Step 2) Initialize EM\n",
    "\n",
    "Below is a class definition `NormPDF` which represents the probability density function (pdf) of the normal distribution with an additional parameter $\\alpha$. The class is explained in the next cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3e13492e93fd5f1ac41f9d062b64209",
     "grade": false,
     "grade_id": "3b2a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class NormPDF():\n",
    "    \"\"\"\n",
    "    A representation of the probability density function of the normal distribution\n",
    "    for the EM Algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mu=0, sigma=1, alpha=1):\n",
    "        \"\"\"\n",
    "        Initializes the normal distribution with mean mu, standard deviation sigma \n",
    "        and proportion of the normal distribution in the mixture alpha.\n",
    "        The defaults are 0, 1, and 1 respectively.\n",
    "        \"\"\"\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.alpha = alpha\n",
    "\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        Returns the evaluation of this normal distribution at x.\n",
    "        Does not take alpha into account!\n",
    "        \"\"\"\n",
    "        return np.exp(-(x - self.mu) ** 2 / (2 * self.sigma ** 2)) / (np.sqrt(np.pi * 2) * self.sigma)\n",
    "\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"\n",
    "        A simple string representation of this instance.\n",
    "        \"\"\"\n",
    "        return 'NormPDF({self.mu:.2f},{self.sigma:.2f},{self.alpha:.2f})'.format(self=self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a0fa2533c31258ae500e7f21f1217aca",
     "grade": false,
     "grade_id": "3b2b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "The class `NormPDF` offers several class methods: `__init__`, `__call__`, `__repr__`. They are all special Python functions which are overloaded so they can be used in a nice way. Note that all methods take as the first parameter `self`: this is just the python way of passing the instance itself to the method so that it becomes possible to access its data. You can always ignore it for now and just assume that the methods only need the parameters which follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22b6956505aeba8d26b4dcaedd575db2",
     "grade": false,
     "grade_id": "3b2c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "scrolled": true
   },
   "source": [
    "`__init__`: This is the constructor. When a new instance of the class is created this method is used. It takes the parameters `mu`, `sigma`, and `alpha`. Note that if you leave out parameters, they will be set to some default values.\n",
    "So you can create `NormPDF` instances like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a10d8794e59e1f7a026e539d0eca5373",
     "grade": false,
     "grade_id": "3b2d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "a = NormPDF()             # No parameters: mu = 0, sigma = 1, alpha = 1\n",
    "b = NormPDF(1)            # mu = 1, sigma = 1, alpha = 1\n",
    "c = NormPDF(1, alpha=0.4) # skips sigma but sets alpha, thus: mu = 1, sigma = 1, alpha = 0.4\n",
    "d = NormPDF(0, 0.5)       # mu = 0, sigma = 0.5, alpha = 1\n",
    "e = NormPDF(0, 0.5, 0.9)  # mu = 0, sigma = 0.5, alpha = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b2d16d076056d8ffd484cd7f4b92a71f",
     "grade": false,
     "grade_id": "3b2e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "`__call__`: This is a very cool feature of Python. By implementing this method one can make an instance *callable*. That basically means one can use it as if it was a function. The `NormPDF` instances can be called with an x value (or a numpy array of x values) to get the evaluation of the normal distribution at x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e211098bfd1324043a83328237f76339",
     "grade": false,
     "grade_id": "3b2f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "normpdf = NormPDF()\n",
    "print(normpdf(0))\n",
    "print(normpdf(0.5))\n",
    "print(normpdf(np.linspace(-2, 2, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3cf9cecf48680271e4b9b3cd9140e024",
     "grade": false,
     "grade_id": "3b2g",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "`__repr__`: This method will be used in Python when one calls `repr(NormPDF())`. As long as `__str__` is not implemented (which you saw in assignment 3c of last week's sheet) `str(NormPDF())` will also use this method. This comes in handy for printing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f0b3ff3894b4589c7029088ec88f610",
     "grade": false,
     "grade_id": "3b2h",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "normpdf1 = NormPDF()\n",
    "normpdf2 = NormPDF(1, 0.5, 0.9)\n",
    "print(normpdf1)\n",
    "print([normpdf1, normpdf2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "274dded14a04c72ba9cf530657d5f362",
     "grade": false,
     "grade_id": "3b2i",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "It is also possible to change the values of an instance of the NormPDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63cc57dd9458996f3a2cbe81e08f0618",
     "grade": false,
     "grade_id": "3b2j",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "normpdf1 = NormPDF()\n",
    "print(normpdf1)\n",
    "print(normpdf1(np.linspace(-2, 2, 10)))\n",
    "\n",
    "normpdf1.mu = 1\n",
    "normpdf1.sigma = 2\n",
    "normpdf1.alpha = 0.9\n",
    "print(normpdf1)\n",
    "print(normpdf1(np.linspace(-2, 2, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "28b0ade192f5f1e05ac41bc24101bc58",
     "grade": false,
     "grade_id": "3b2k",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now that you know how the `NormPDF` class works, it is time for the implementation of the initialization function. Here is the task again:\n",
    "\n",
    "Write a function `gaussians = initialize_EM(data, num_distributions)` to initialize the EM.\n",
    "\n",
    "Each normal distribution $j$ has three parameters: $\\mu_j$ (the mean), $\\sigma_j$ (the standard deviation), $\\alpha_j$ (the proportion of the normal distribution in the mixture, that means $\\sum\\limits_j\\alpha_j=1$).\n",
    "Initialize the three parameters using three random partitions $S_j$ of the data set. Calculate each $\\mu_j$ and $\\sigma_j$ and set $\\alpha_j = \\frac{|S_j|}{|X|}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b95ffade288455ea3916aa1eabb92b2",
     "grade": true,
     "grade_id": "3b2_code",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def initialize_EM(data, num_distributions):\n",
    "    \"\"\"\n",
    "    Initializes the EM algorithm by calculating num_distributions NormPDFs\n",
    "    from a random partitioning of data. I.e., the data set is randomly\n",
    "    divided into num_distribution parts, and each part is used to initialize\n",
    "    mean, standard deviation and alpha parameter of a NormPDF object.\n",
    "    \n",
    "    Args:\n",
    "        data (array): A collection of data.\n",
    "        num_distributions (int): The number of distributions to return.\n",
    "        \n",
    "    Returns:\n",
    "        A list of num_distribution NormPDF objects, initialized from a\n",
    "        random partioning of the data.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE ##########################################\n",
    "    # randomly determine the partition [0, num_distributions] for each data point\n",
    "    partitioning = np.random.randint(0, num_distributions, len(data))\n",
    "\n",
    "    print(partitioning)\n",
    "\n",
    "    # initialize normal distributions\n",
    "    normal_distributions = [NormPDF() for i in range(num_distributions)]\n",
    "    # compute properties of normal dist for each partition\n",
    "    for partition in range(len(normal_distributions)):\n",
    "        # build up list of data points for current partition\n",
    "        data_for_partition = [data[i] for i in range(len(data)) if partitioning[i] == partition]\n",
    "\n",
    "        # compute properties\n",
    "        normal_distributions[partition].mu = np.mean(data_for_partition)\n",
    "        normal_distributions[partition].sigma = np.std(data_for_partition)\n",
    "        normal_distributions[partition].alpha = len(data_for_partition) / len(data)\n",
    "\n",
    "    ###########################################################\n",
    "    return normal_distributions\n",
    "\n",
    "\n",
    "normpdfs_ = initialize_EM(np.linspace(-1, 1, 100), 2)\n",
    "assert len(normpdfs_) == 2, \"The number of initialized distributions is not correct.\"\n",
    "# 1e-10 is 0.0000000001\n",
    "assert abs(1 - sum([normpdf.alpha for normpdf in normpdfs_])) < 1e-10 , \"Sum of all alphas is not 1.0!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1dc7394ede5c8e447eca17053b6cd144",
     "grade": false,
     "grade_id": "3b3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Step 3) Implement the expectation step\n",
    "\n",
    "Perform a soft classification of the data samples with the normal distributions. That means: Calculate the likelihood that a data sample $x_i$ belongs to distribution $j$ given parameters $\\mu_j$ and $\\sigma_j$. Or in other words, what is the likelihood of $x_i$ to be drawn from $N_j(\\mu_j, \\sigma_j)$? When you got the likelihood, weight the result by $\\alpha_j$.\n",
    "\n",
    "As a last step normalize the results such that the likelihoods of a data sample $x_i$ sum up to $1$.\n",
    "\n",
    "*Hint:* Store the data in a different array before you normalize it to not run into problems with partly normalized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b0f481312f674ff686c6567090b70c9",
     "grade": true,
     "grade_id": "3b3_code",
     "locked": false,
     "points": 2.5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def expectation_step(gaussians, data):\n",
    "    \"\"\"\n",
    "    Performs the expectation step of the EM.\n",
    "    \n",
    "    Args:\n",
    "        gaussians (list): A list of NormPDF objects.\n",
    "        data (array): The data vector.\n",
    "        \n",
    "    Returns:\n",
    "        An array of shape (len(data), len(gaussians))\n",
    "        which contains normalized likelihoods for each sample\n",
    "        to denote to which of the normal distributions it \n",
    "        most likely belongs to.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # create array of shape (len(data), len(gaussians))\n",
    "    expectation = np.zeros((len(data), len(gaussians)))\n",
    "\n",
    "    # set likelihoods for each sample\n",
    "    for idx in range(len(gaussians)):\n",
    "        expectation[:,idx] = gaussians[idx](data) * gaussians[idx].alpha\n",
    "\n",
    "    # normalize results\n",
    "    # --> divide each number in the sample by the sum of all the numbers in the sample\n",
    "    norm_expectation = np.zeros((len(data), len(gaussians)))\n",
    "    for idx in range(len(gaussians)):\n",
    "        # sum of each sub-array\n",
    "        list_of_likelihood_sums = np.sum(expectation, 1)\n",
    "        curr_sample = expectation[:,idx]\n",
    "        # normalize\n",
    "        norm_expectation[:,idx] = [curr_sample[i] / list_of_likelihood_sums[i] for i in range(len(curr_sample))]\n",
    "\n",
    "    return norm_expectation\n",
    "    \n",
    "\n",
    "assert expectation_step([NormPDF(), NormPDF()], np.linspace(-2, 2, 100)).shape == (100, 2) , \"Shape is not correct!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b681f42617531523ddc94caef30b5b3a",
     "grade": false,
     "grade_id": "3b4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### Step 4) Implement the maximization step\n",
    "\n",
    "In the maximization step each $\\mu_j$, $\\sigma_j$ and $\\alpha_j$ is updated. First calculate the new means:\n",
    "\n",
    "$$\\mu_j = \\frac{1}{\\sum\\limits_{i=1}^{|X|} p_{ij}} \\sum\\limits_{i=1}^{|X|} p_{ij}x_i$$\n",
    "\n",
    "That means $\\mu_j$ is the weighted mean of all samples, where the weight is their likelihood of belonging to distribution $j$.\n",
    "\n",
    "Then calculate the new $\\sigma_j$. Each new $\\sigma_j$ is the standard deviation of the normal distribution with the new $\\mu_j$, so for the calculation you already use the new $\\mu_j$:\n",
    "\n",
    "$$\\sigma_j = \\sqrt{ \\frac{1}{\\sum\\limits_{i=1}^{|X|} p_{ij}} \\sum\\limits_{i=1}^{|X|} p_{ij} \\left(x_i - \\mu_j\\right)^2 }$$\n",
    "\n",
    "To calculate the new $\\alpha_j$ for each distribution, just take the mean of $p_j$ for each normal distribution $j$.\n",
    "\n",
    "**Caution:** For the next step it is necessary to know how much all $\\mu$ and $\\sigma$ changed. For that the function `maximization_step` should return a numpy array of those (absolute) changes. For example if $\\mu_0$ changed from 0.1 to 0.15, $\\sigma_0$ from 1 to 0.9, $\\mu_1$ from 0.5 to 0.6, and $\\sigma_1$, $\\mu_2$, and $\\sigma_2$ stayed the same, we expect the function to return `np.array([0.05, 0.1, 0.1, 0, 0, 0])` (however, the order is not important)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0c8f756e23c34671c3ab1ce2af7b8e9",
     "grade": true,
     "grade_id": "3b4_code",
     "locked": false,
     "points": 2.5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def maximization_step(gaussians, data, expectation):\n",
    "    \"\"\"\n",
    "    Performs the maximization step of the EM.\n",
    "    Modifies the gaussians by updating their mus and sigmas.\n",
    "    \n",
    "    Args:\n",
    "        gaussians (list): A list of NormPDF objects.\n",
    "        data (array): The data vector.\n",
    "        expectation (array): The expectation values for data element\n",
    "            (as computed by expectation_step()).\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of absolute changes in any mu or sigma, \n",
    "        that means the returned array has twice as many elements as\n",
    "        the supplied list of gaussians.\n",
    "    \"\"\"\n",
    "    changes = []\n",
    "    # YOUR CODE HERE\n",
    "    for idx in range(len(gaussians)):\n",
    "\n",
    "        # p_ij is data point i in distribution j\n",
    "\n",
    "        # update mu\n",
    "        data_points_in_curr_dist = expectation[:,idx]\n",
    "        products = [data_points_in_curr_dist[i] * data[i] for i in range(len(data))]\n",
    "        mu = np.sum(products) / np.sum(data_points_in_curr_dist)\n",
    "        # update sigma\n",
    "        products = [data_points_in_curr_dist[i] * ((data[i] - mu) ** 2) for i in range(len(data))]\n",
    "        sigma = np.sqrt(np.sum(products) / np.sum(data_points_in_curr_dist))\n",
    "        # update alpha\n",
    "        alpha = np.mean(data_points_in_curr_dist)\n",
    "\n",
    "        changes.append(abs(gaussians[idx].mu - mu))\n",
    "        changes.append(abs(gaussians[idx].sigma - sigma))\n",
    "\n",
    "        gaussians[idx].mu = mu\n",
    "        gaussians[idx].sigma = sigma\n",
    "        gaussians[idx].alpha = alpha\n",
    "\n",
    "    return np.array(changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ba65c711e6d7fbe7f85285a51fa9635",
     "grade": false,
     "grade_id": "3b5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**5) Perform the complete EM and plot your results:**\n",
    "\n",
    "Initialize three normal distributions whose parameters will be changed iteratively by the EM to converge close to the original distributions.\n",
    "\n",
    "Build a loop around the iterative procedure of expectation and maximization which stops when the changes in all $\\mu_j$ and $\\sigma_j$ are sufficiently small enough.\n",
    "\n",
    "Plot your results after each step and mark which data points belong to which normal distribution. If you don't get it to work, just plot your final solution.\n",
    "\n",
    "*Hint:* Remember to load the data and initialize the EM before the loop.\n",
    "\n",
    "*Hint:* A function `plot_intermediate_result` to plot your result after each step is already defined in the next cell. Take a look at what arguments it takes and try to use it in your loop.\n",
    "\n",
    "*Hint:* To plot your final result the first three images and corresponding code examples on the tutorial of [`plt.plot(...)`](http://matplotlib.org/users/pyplot_tutorial.html) should help you.\n",
    "\n",
    "*Optional:* Run the code multiple times. If your results are changing, use `np.random.seed(2)` in the beginning of the cell to get consistent results (any other integer will work as well, but 2 has some good results for the example solutions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba9f8e778675b911374922fac2ac48ee",
     "grade": true,
     "grade_id": "3b5_code",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Sets the random seed to a fix value to make results consistent\n",
    "np.random.seed(2)\n",
    "\n",
    "colors = itertools.cycle(['r', 'g', 'b', 'c', 'm', 'y', 'k'])\n",
    "figure, axis = plt.subplots(1)\n",
    "axis.set_xlim(-5, 5)\n",
    "axis.set_ylim(-0.2, 4)\n",
    "axis.set_title('Intermediate Results')\n",
    "plt.figure('Final Result')\n",
    "\n",
    "def plot_intermediate_result(gaussians, data, mapping):\n",
    "    \"\"\"\n",
    "    Gets a list of gaussians and data input. The mapping\n",
    "    parameter is a list of indices of gaussians. Each value\n",
    "    corresponds to the data value at the same position and \n",
    "    maps this data value to the proper gaussian.\n",
    "    \"\"\"\n",
    "    x = np.linspace(-5, 5, 100)\n",
    "    if len(axis.lines):\n",
    "        for j, N in enumerate(gaussians):\n",
    "            axis.lines[j * 2].set_xdata(x)\n",
    "            axis.lines[j * 2].set_ydata(N(x))\n",
    "            axis.lines[j * 2 + 1].set_xdata(data[mapping == j])\n",
    "            axis.lines[j * 2 + 1].set_ydata([0] * len(data[mapping == j]))\n",
    "    else:\n",
    "        for j, N in enumerate(gaussians):\n",
    "            axis.plot(x, N(x), data[mapping == j], [0] * len(data[mapping == j]), 'x', color=next(colors), markersize=5)\n",
    "    figure.canvas.draw()\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    \n",
    "# Perform the initialization.\n",
    "data = load_data('em_normdistdata.txt')\n",
    "gaussians = initialize_EM(data, 3)\n",
    "\n",
    "# Loop until the changes are small enough.\n",
    "eps = 0.05\n",
    "changes = [float('inf')] * 2\n",
    "\n",
    "while max(changes) > eps:\n",
    "    # Iteratively apply the expectation step, followed by the maximization step.\n",
    "    \n",
    "    # YOUR CODE HERE ##########################\n",
    "    expectation = expectation_step(gaussians, data)\n",
    "    changes = maximization_step(gaussians, data, expectation)\n",
    "    ###########################################\n",
    "\n",
    "    # Optional: Calculate the parameters to update the plot and call the function to do it.\n",
    "    plot_intermediate_result(gaussians, data, np.argmax(expectation, 1))\n",
    "\n",
    "\n",
    "# Plot your final result and print the final parameters.\n",
    "# YOUR CODE HERE\n",
    "print(\"final parameters:\", gaussians)\n",
    "plot_intermediate_result(gaussians, data, np.argmax(expectation, 1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda475831754d4f421c8b9b78a005f24ea9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}