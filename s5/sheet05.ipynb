{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "eb881b440faff8e8427d5a2861f39e9f",
     "grade": false,
     "grade_id": "h00",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Osnabr√ºck University - Machine Learning (Summer Term 2020) - Prof. Dr.-Ing. G. Heidemann, Ulf Krumnack, Axel Schaffland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f01b02cef2683e03ee455e98b30f6f5c",
     "grade": false,
     "grade_id": "h01",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Exercise Sheet 05: Dimension Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "heading_collapsed": true,
    "nbgrader": {
     "checksum": "eeba2e442fa2764c11d978caef72a573",
     "grade": false,
     "grade_id": "h02",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This week's sheet should be solved and handed in before the end of **Saturday, May 30, 2020**. If you need help (and Google and other resources were not enough), feel free to contact your groups designated tutor or whomever of us you run into first. Please upload your results to your group's Stud.IP folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "20ee1eaee75301849f3c518d43a914f2",
     "grade": false,
     "grade_id": "cell-0ceaa7378e4a713d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 0: Math recap (Derivatives in higher dimensions) [0 Points]\n",
    "\n",
    "This exercise is supposed to be very easy but in this and the following sheets we will give points. There will be a similar exercise on every sheet. It is intended to revise some basic mathematical notions that are assumed throughout this class and to allow you to check if you are comfortable with them. Usually you should have no problem to answer these questions offhand, but if you feel unsure, this is a good time to look them up again. You are always welcome to discuss questions with the tutors or in the practice session. Also, if you have a (math) topic you would like to recap, please let us know."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6eb9238f1420f5fae66c47669e8d567d",
     "grade": false,
     "grade_id": "cell-106b918b6f9c6fea",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** What is a partial derivative? What is a directional derivative? How are these computed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "36475d2d0f85070bc2f5c7617633e228",
     "grade": true,
     "grade_id": "cell-f80e2cfbc5dae96a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "33165181f1f536046a89dea273b1dd3c",
     "grade": false,
     "grade_id": "cell-10c6f038150609e1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**b)** What is the gradient, the Jacobian matrix, and the Hessian matrix? How are they computed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4ff3d7e15d56e4dbc54eaef465500577",
     "grade": true,
     "grade_id": "cell-c45db6ae30a5507a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8ce944e185f8cdab12815c71da691493",
     "grade": false,
     "grade_id": "cell-7822385798587c45",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**c)** What is the chain rule (in calculus)? How does it look in the higher-dimensional case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "94696dd22018d912b2a84a73c0a13030",
     "grade": true,
     "grade_id": "cell-1a5e17baf68e02e1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    },
    "solution": true
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "checksum": "5fff736d22c11bf3b5c3a1ff705c2c43",
     "grade": false,
     "grade_id": "ex1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 1: Curse of Dimensionality [5 Points]\n",
    "\n",
    "For the following exercise, be detailed in your answers and provide some examples. Think about keywords like: random vectors in high dimensional space, manifolds and Bertillonage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "checksum": "c82010f68e7434a489841f7cdedd8442",
     "grade": false,
     "grade_id": "ex1_a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**a)** What are the curse of dimensionality and its implication for pattern classification? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "hidden": true,
    "nbgrader": {
     "checksum": "d26d8a53a81b62acb56efb18efe45591",
     "grade": true,
     "grade_id": "ex1_a_solution",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "checksum": "c3ea2c6702a7f9c037c56ec86e64f9da",
     "grade": false,
     "grade_id": "ex1_b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**b)** Explain how this phenomenom could be used to one's advantage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "hidden": true,
    "nbgrader": {
     "checksum": "f8b9810e6a1f28473be5497241413e7b",
     "grade": true,
     "grade_id": "ex1_b_solution",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "checksum": "131868a391e6695a8f1273960e3dc171",
     "grade": false,
     "grade_id": "ex1_c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**c)** Explain in your own words the concepts of descriptive and intrinsic dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "hidden": true,
    "nbgrader": {
     "checksum": "5e9bae1c3fb4af5de4cba4f757e00584",
     "grade": true,
     "grade_id": "ex1_c_solution",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7746eba43118373283840b64631343a0",
     "grade": false,
     "grade_id": "cell-4b2a7291c0d81d1a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**d)** The $n$-dimensional unit cube: A cube with edge length $d=1$ in the $n$-dimensional space $\\mathbb{R}^n$. Compute the volume and the length of the diagonal for $n = 1, 2, 3, 4, 5, 10, 100, 1000$. Do the same for $d=\\frac{1}{2}$. Discuss the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "58694a7912a5df0a4741953a1013ebfc",
     "grade": true,
     "grade_id": "cell-70999ba1b1b35036",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "949f02f5f8e7a6f31b80900a3782c888",
     "grade": true,
     "grade_id": "cell-16d9afe9225178e8",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6ddb794b9e27cba6ba60299ef46573ee",
     "grade": false,
     "grade_id": "cell-f981fd573a23eed2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "**e)** The $n$-dimensional unit ball: A ball with radius $r=1$ in the $n$-dimensional space $\\mathbb{R}^n$. Compute the volume for $n = 1,2,3,5,10,100,300,400$. Refer to https://en.wikipedia.org/wiki/Volume_of_an_n-ball for the formulae. \n",
    "\n",
    "Consider a $n$-dimensional unit orange consisting of the peel and the pulp: Let the thickness of the peel be $1\\%$ of the radius. Compute the volume of the peel and compare to the volume of the whole orange for the same values of $n$. State the implications of your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "662e42fb811b8fe6f900a68798fbd134",
     "grade": true,
     "grade_id": "cell-8d659c961b351eac",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7a9d6857bb4857c7d9d68384be570bb2",
     "grade": true,
     "grade_id": "cell-bee514604d4d11a9",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4812406918f98bb23619b761496c3759",
     "grade": false,
     "grade_id": "ex2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 2: Implement and Apply PCA [8 Points]\n",
    "\n",
    "In this assignment you will implement PCA from the ground up and apply it to the `cars` dataset (simplified from the JSE [2004 New Car and Truck Data](http://www.amstat.org/publications/jse/jse_data_archive.htm)). This dataset consists of measurements taken on 97 different cars. The eleven features measured are: Suggested retail price (USD), Price to dealer (USD), Engine size (liters), Number of engine cylinders, Engine horsepower, City gas mileage, Highway gas mileage, Weight (pounds), Wheelbase (inches), Length (inches) and Width (inches). \n",
    "\n",
    "We would like to visualize these high dimensional features to get a feeling for how the cars relate to each other so we need to find a subspace of dimension two or three into which we can project the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "325114529c4799bcf74afdf8403f3b99",
     "grade": true,
     "grade_id": "ex2_a_solution",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# TODO: Load the cars dataset in cars.csv .\n",
    "# YOUR CODE HERE\n",
    "\n",
    "assert cars.shape == (97, 11), \"Shape is not (97, 11), was {}\".format(cars.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1d4f4d4287acb712e068a0cf6f5e7c32",
     "grade": false,
     "grade_id": "cell-f34c576eec4a5968",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Excecute the following code which will create a scatter plot matrix (it might take some time to execute). This should give you an idea about trends and correlations in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ce1e45b9c828f363a20fc8b0213a0a5e",
     "grade": false,
     "grade_id": "cell-dea96f209e45dc32",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "cols = ['Suggested retail price (USD)', 'Price to dealer (USD)', \n",
    "          'Engine size (liters)', 'Number of engine cylinders', \n",
    "          'Engine horsepower', 'City gas mileage' , \n",
    "          'Highway gas mileage', 'Weight (pounds)', \n",
    "          'Wheelbase (inches)', 'Length (inches)', 'Width (inches)']\n",
    "\n",
    "df = pd.DataFrame(cars, columns=cols)\n",
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a70c090d0d56e70c7252fd74bfe83887",
     "grade": false,
     "grade_id": "ex2_b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "As a first step we need to normalize the data such that they have a zero mean and a unit standard deviation. Use the standard score for this:\n",
    "$$\\frac{X - \\mu}{\\sigma}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f2733a4fabf7cf3c046539245ffb9e0b",
     "grade": true,
     "grade_id": "ex2_b_solution",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# TODO: Normalize the data and store them in a variable called cars_norm.\n",
    "# YOUR CODE HERE\n",
    "\n",
    "assert cars_norm.shape == (97, 11), \"Shape is not (97, 11), was {}\".format(cars.shape)\n",
    "assert np.abs(np.sum(cars_norm)) < 1e-10, \"Absolute sum was {} but should be close to 0\".format(np.abs(np.sum(cars_norm)))\n",
    "assert np.abs(np.sum(cars_norm ** 2) / cars_norm.size - 1) < 1e-10, \"The data is not normalized, sum/N was {} not 1\".format(np.sum(cars_norm ** 2) / cars_norm.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "52dd8248ffca212450cf103f4ee8de66",
     "grade": false,
     "grade_id": "cell-b2aebe0aabf8db03",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "What is the covariance matrix of a dataset? What do the different entries of the matrix mean? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7e38327010723cbbf66fd5dc57ad3d4e",
     "grade": true,
     "grade_id": "cell-bd9c31f2e24eac43",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2c08cbf4e82a0eb95fcd1f722cd91f1b",
     "grade": false,
     "grade_id": "ex2_c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "PCA finds a subspace that maximizes the variance by determining the eigenvectors of the (auto)covariance matrix. So we need to calculate the covariance matrix and afterwards the eigenvalues. When the data is normalized the autocovariance is calculated as\n",
    "$$C = X^T\\cdot X$$\n",
    "with $X$ being an $m \\times n$ matrix with $n$ features and $m$ samples.\n",
    "The entry $c_{i,j}$ in $C$ tells you how much feature $i$ correlates with feature $j$. \n",
    "(Note: sometimes the formula $C=X\\cdot X^T$ can be found, i.e., with rows and columns swapped. This depends on whether your put the individual datapoints as rows or columns in you matrix $X$. However, in the end you want to know how the individual features correlate, i.e., in our example you want a $11\\times11$-matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b5a9821a2e754738708a1bcbdfc11f04",
     "grade": true,
     "grade_id": "ex2_c_solution",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# TODO: Compute the autocovariance matrix and store it into autocovar\n",
    "# YOUR CODE HERE\n",
    "\n",
    "assert autocovar.shape == (11, 11)\n",
    "\n",
    "# TODO: Compute the eigenvalues und eigenvectors and store them into eigenval and eigenvec\n",
    "#       (Figure out a function to do this for you)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "assert eigenval.shape == (11,)\n",
    "\n",
    "assert eigenvec.shape == (11, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "456ade44adf5b4bcd90be2a36a3d101e",
     "grade": false,
     "grade_id": "cell-3573629c4379a229",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Plot the spectrum of the eigenvalues to make sure that they are sorted by their magnitude. How many principal components should you include based on the spectrum plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "af4ff9edadd0b7ac23e7187992b1cf84",
     "grade": true,
     "grade_id": "cell-53f8a29f237fc60d",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4e8e9da6d36f943a1cdce9a96208094e",
     "grade": false,
     "grade_id": "ex2_d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now you should have a matrix full of eigenvectors. We can now do two things: project the data down onto the two dimensional subspace to visualize it and we can also plot the two first principle component vectors as eleven two dimensional points to get a feeling for how the features are projected into the subspace. Execute the cells below and describe what you see. Is PCA a good method for this problem? Was it justifiable that we only considered the first two principle components? What kinds of cars are in the four quadrants of the first plot? (**put your answer in the cell below of this code cell**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cd5fa841b3e6c87441fdd70f27acacb4",
     "grade": false,
     "grade_id": "cell-a2968be21ca0a091",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Project the data down into the two dimensional subspace\n",
    "proj = cars_norm @ eigenvec[:,0:2]\n",
    "\n",
    "# Plot projected data\n",
    "fig = plt.figure('Data projected onto first two Principal Components')\n",
    "fig.gca().set_xlim(-8, 8)\n",
    "fig.gca().set_ylim(-4, 7)\n",
    "plt.scatter(proj[:,0], proj[:,1])\n",
    "# Divide plot into quadrants\n",
    "plt.axhline(0, color='green')\n",
    "plt.axvline(0, color='green')\n",
    "# force drawing on 'run all'\n",
    "fig.canvas.draw()\n",
    "\n",
    "# Plot eigenvectors\n",
    "eig_fig = plt.figure('Eigenvector plot')\n",
    "plt.scatter(eigenvec[:,0], eigenvec[:,1])\n",
    "\n",
    "# add labels\n",
    "labels = ['Suggested retail price (USD)', 'Price to dealer (USD)', \n",
    "          'Engine size (liters)', 'Number of engine cylinders', \n",
    "          'Engine horsepower', 'City gas mileage' , \n",
    "          'Highway gas mileage', 'Weight (pounds)', \n",
    "          'Wheelbase (inches)', 'Length (inches)', 'Width (inches)']\n",
    "for label, x, y in zip(labels, eigenvec[:,0], eigenvec[:,1]):\n",
    "    plt.annotate(\n",
    "        label, xy = (x, y), xytext = (-20, 20),\n",
    "        textcoords = 'offset points', ha = 'left', va = 'bottom',\n",
    "        bbox = dict(boxstyle = 'round,pad=0.5', fc = 'blue', alpha = 0.5),\n",
    "        arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))\n",
    "# force drawing on 'run all'\n",
    "eig_fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e582879d8311a72a87b382a34ab12773",
     "grade": true,
     "grade_id": "ex2_d_solution",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "heading_collapsed": true,
    "nbgrader": {
     "checksum": "54950079120a9d262a72ebe5938eb90e",
     "grade": false,
     "grade_id": "ex3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Assignment 3: PCA [3 Points]\n",
    "\n",
    "In this exercise we investigate the statement from the lecture that PCA finds the subspace that captures most of the data variance. To be more precise, we show that the orthonormal projection onto an $m$-dimensional subspace that maximizes the variance of the projected data is defined by the principal components, i.e. by the $m$ eigenvectors of the autocorrelation matrix $C$ corresponding to the $m$ largest eigenvalues. The proof consists of two steps. In this exercise you will only proof the first step:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "checksum": "d6317915cba86649ff2cb6f80ec68a8d",
     "grade": false,
     "grade_id": "ex3_a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### First step:\n",
    "Consider a one dimensional subspace: Determine a (unit) vector $\\vec{p}$, such that the variance of the data, when projected onto the subspace determined by that vector, is maximal.\n",
    "\n",
    "The autocorrelation matrix $C$ allows to compute the variance of the projected data as $\\vec{p}^{T}C\\vec{p}$. We want to maximize this expression. To avoid $\\|\\vec{p}\\|\\to\\infty$ we will only consider unit vectors, i.e. we constrain $\\vec{p}$ to be normalized: $\\vec{p}^T\\vec{p}=1$. Maximize the expression with this constraint (which can be done using a Lagrangian multiplier). Conclude that a suitable $\\vec{p}$ has to be an eigenvector of $C$ and describe which of the eigenvectors is optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "hidden": true,
    "nbgrader": {
     "checksum": "7e80b023dcc7cccd3fb26e1a54161529",
     "grade": true,
     "grade_id": "ex3_a_solution",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "nbgrader": {
     "checksum": "38bda87c9767782aa3323595aaf98116",
     "grade": false,
     "grade_id": "ex3_b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Second step:\n",
    "(Outline for the interested reader. You do not have to solve this second part.)\n",
    "\n",
    "In the second step the statement for the general case of an $m$-dimensional projection space is proofed by induction:\n",
    "\n",
    "Assume the statement has been shown for the $(m-1)$-dimensional projection space, spanned by the $m-1$ (orthonormal) eigenvectors $\\vec{p}_1,\\ldots,\\vec{p}_{m-1}$ corresponding to the $(m-1)$ largest eigenvalues $\\lambda_1,\\ldots,\\lambda_{m-1}$. Now find a (unit) vector $\\vec{p}_m$, orthogonal to the existing vectors $\\vec{p}_1,\\ldots,\\vec{p}_{m-1}$, that maximizes the projected variance $\\vec{p}_m^TC\\vec{p}_m$. Proceed similar to the first step, but with additional Lagrangian multipliers to enforce the orthogonality constraint. One can then show that the new vector $\\vec{p}_m$ is an eigenvector of $C$. Finally it can be shown that the variance is maximized for the eigenvector corresponding to the $m$-th largest eigenvalue $\\lambda_m$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1edc68066ccb517eff5424b182e4672f",
     "grade": true,
     "grade_id": "cell-e302aa2226cfa4fc",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}